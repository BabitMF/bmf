{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxI1JxQ5-P_V"
      },
      "source": [
        "# getting ready\n",
        "安装相关依赖"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step1 从googledrive 下载onnx模型 命名为aes_transonnx_update3.onnx后放到models文件夹下\n"
      ],
      "metadata": {
        "id": "srI36yYZ_V2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1F8W4pbHpCzSYNqvYo9M7W5i0cTDRdwqp/view?usp=drive_link -O models/"
      ],
      "metadata": {
        "id": "ZbGVuigI_O5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b311f2-638b-4b68-c4c4-32b34561d326"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1F8W4pbHpCzSYNqvYo9M7W5i0cTDRdwqp\n",
            "To: /content/models/aes_transonnx_update3.onnx\n",
            "100% 187M/187M [00:03<00:00, 58.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2 安装测试视频、bmf-module、onnxruntime-module"
      ],
      "metadata": {
        "id": "V5R2gGuo_k7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpvU1uEd-jp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0bb12f-ad6d-4a54-c555-5a103d906c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vvUssyc8GC8SPzVdYwRwKc2OvyKGY-Px\n",
            "To: /content/bbb_360_20s.mp4\n",
            "100% 1.13M/1.13M [00:00<00:00, 112MB/s]\n",
            "Collecting BabitMF\n",
            "  Downloading BabitMF-0.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from BabitMF) (1.22.4)\n",
            "Installing collected packages: BabitMF\n",
            "Successfully installed BabitMF-0.0.5\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1vvUssyc8GC8SPzVdYwRwKc2OvyKGY-Px/view?usp=sharing # 测试视频\n",
        "!pip install BabitMF\n",
        "!pip3 install onnxruntime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step3 测试modules和model文件可以正常"
      ],
      "metadata": {
        "id": "cTsnAaR57zwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bmf\n",
        "import sys\n",
        "import onnxruntime as ort\n",
        "from module_utils import SyncModule\n",
        "import aesmod_module\n",
        "import onnxruntime as ort\n",
        "import os.path as osp\n",
        "model_dir = osp.join(osp.abspath(osp.dirname('__file__')), 'models')\n",
        "aesmod_ort_model_path = osp.realpath(osp.join(model_dir, 'aes_transonnx_update3.onnx'))\n",
        "print(aesmod_ort_model_path)\n",
        "ort_session = ort.InferenceSession(aesmod_ort_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJaxbai9NwsJ",
        "outputId": "5b78af05-468e-41b3-9a5a-37ef2a3f9ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/aes_transonnx_update3.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLmIr9To8Wui"
      },
      "source": [
        "# source code\n",
        "\n",
        "##aesmod_module.py\n",
        "\n",
        "\n",
        "*   func get_logger()\n",
        "*   func flex_resize_aesv2()\n",
        "*   class Aesmod\n",
        "*   class BMFAesmod\n",
        "\n",
        "\n",
        "##module_utils.py\n",
        "\n",
        "\n",
        "*   class SyncModule\n",
        "\n",
        "\n",
        "##main.py\n",
        "main program for calling bmf api and visualize output\n",
        "*   func segment_decode_ticks()\n",
        "*   func get_duration()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A7Ul2r64l0a",
        "outputId": "545209bc-18de-4ff1-bc45-579a7ff55542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing aesmod_module.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile aesmod_module.py\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from module_utils import SyncModule\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pdb\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
        "import onnxruntime as ort\n",
        "import torch\n",
        "import logging\n",
        "import cv2\n",
        "\n",
        "def get_logger():\n",
        "    return logging.getLogger(\"main\")\n",
        "\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "\n",
        "def flex_resize_aesv2(img, desired_size=[448, 672], pad_color=[0, 0, 0]):\n",
        "    old_h, old_w = img.shape[:2]  # old_size is in (height, width) format\n",
        "    if desired_size[0] >= desired_size[1]:\n",
        "        if old_h < old_w:  # rotate the honrizontal video\n",
        "            img = np.rot90(img, k=1, axes=(1, 0))\n",
        "    else:\n",
        "        if old_h > old_w:  # rotate the vertical video\n",
        "            img = np.rot90(img, k=1, axes=(1, 0))\n",
        "    old_h, old_w = img.shape[:2]\n",
        "\n",
        "    if old_w / old_h > (desired_size[1] / desired_size[0]):\n",
        "        ratio = desired_size[0] / old_h\n",
        "    else:\n",
        "        ratio = desired_size[1] / old_w\n",
        "    img = cv2.resize(img, None, fx=ratio, fy=ratio)\n",
        "    h, w, _ = img.shape\n",
        "    h_crop = (h - desired_size[0]) // 2\n",
        "    w_crop = (w - desired_size[1]) // 2\n",
        "    img = img[h_crop : h_crop + desired_size[0], w_crop : w_crop + desired_size[1], :]\n",
        "    return img\n",
        "\n",
        "\n",
        "class Aesmod:\n",
        "    def __init__(self, model_version, output_path):\n",
        "        self._frm_idx = 0\n",
        "        self._frm_scores = []\n",
        "        self._model_version = model_version\n",
        "        self._output_path = output_path\n",
        "\n",
        "        model_dir = osp.join(osp.abspath(osp.dirname(\"__file__\")), \"models\")\n",
        "        self.use_gpu = False\n",
        "        aesmod_ort_model_path = osp.realpath(\n",
        "            osp.join(model_dir, \"aes_transonnx_update3.onnx\")\n",
        "        )\n",
        "        print(aesmod_ort_model_path)\n",
        "        LOGGER.info(\"loading aesthetic ort inference session\")\n",
        "        self.ort_session = ort.InferenceSession(aesmod_ort_model_path)\n",
        "\n",
        "        self.resize_reso = [672, 448]\n",
        "\n",
        "    def preprocess(self, frame):\n",
        "        frame = flex_resize_aesv2(frame)\n",
        "        # print('using flex_resize_aesv2', frame.shape)\n",
        "        frame = (\n",
        "            frame.astype(np.float32) / 255.0\n",
        "            - np.array([0.485, 0.456, 0.406], dtype=\"float32\")\n",
        "        ) / (np.array([0.229, 0.224, 0.225], dtype=\"float32\"))\n",
        "        frame = np.transpose(frame, (2, 0, 1))\n",
        "        frame = np.expand_dims(frame, 0)\n",
        "        return frame\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_to_list(tensor):\n",
        "        if tensor.requires_grad:\n",
        "            return tensor.detach().cpu().flatten().tolist()\n",
        "        else:\n",
        "            return tensor.cpu().flatten().tolist()\n",
        "\n",
        "    @staticmethod\n",
        "    def score_pred_mapping(raw_scores, raw_min=2.60, raw_max=7.42):\n",
        "        pred_score = np.clip(\n",
        "            np.sum([x * (i + 1) for i, x in enumerate(raw_scores)]), raw_min, raw_max\n",
        "        )\n",
        "        pred_score = np.sqrt((pred_score - raw_min) / (raw_max - raw_min))* 100\n",
        "        return float(np.clip(pred_score, 0, 100.0))\n",
        "\n",
        "\n",
        "    def process(self, frames):\n",
        "        frames = [\n",
        "            frame if frame.flags[\"C_CONTIGUOUS\"] else np.ascontiguousarray(frame)\n",
        "            for frame in frames\n",
        "        ]\n",
        "        frame = self.preprocess(frames[0])\n",
        "        print(\"after preprocess shape\", frame.shape)\n",
        "        if not frame.flags[\"C_CONTIGUOUS\"]:\n",
        "            frame = np.ascontiguousarray(frame, dtype=np.float32)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if self.use_gpu:\n",
        "            with torch.no_grad():\n",
        "                input_batch = torch.from_numpy(frame).contiguous().cuda()\n",
        "                preds, _ = self.trt_model(input_batch)\n",
        "                raw_score = self.tensor_to_list(preds)\n",
        "        else:\n",
        "\n",
        "            raw_score = self.ort_session.run(None, {\"input\": frame})\n",
        "            raw_score = raw_score[0][0]\n",
        "        score = self.score_pred_mapping(raw_score, 0, 10)\n",
        "        self._frm_scores.append(score)\n",
        "        self._frm_idx += 1\n",
        "        t2 = time.time()\n",
        "        LOGGER.info(f\"[Aesmod] inference time: {(t2 - t1)*1000:0.1f} ms\")\n",
        "        return frames[0]\n",
        "\n",
        "    def clean(self):\n",
        "        nr_score = round(np.mean(self._frm_scores), 2)\n",
        "        results = {\"aesthetic\": nr_score, \"aesthetic_version\": self._model_version}\n",
        "        LOGGER.info(f\"overall prediction {json.dumps(results)}\")\n",
        "        with open(self._output_path, \"w\") as outfile:\n",
        "            json.dump(results, outfile, indent=4, ensure_ascii=False)\n",
        "\n",
        "\n",
        "class BMFAesmod(SyncModule):\n",
        "    def __init__(self, node=None, option=None):\n",
        "        output_path = option.get(\"output_path\", 0)\n",
        "        model_version = option.get(\"model_version\", \"v1.0\")\n",
        "        self._nrp = Aesmod(model_version, output_path)\n",
        "        SyncModule.__init__(self, node, nb_in=1, in_fmt=\"rgb24\", out_fmt=\"rgb24\")\n",
        "\n",
        "    def core_process(self, frames):\n",
        "        return self._nrp.process(frames)\n",
        "\n",
        "    def clean(self):\n",
        "        self._nrp.clean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNJQBWSE7LLX",
        "outputId": "f16b1ad5-0482-4759-812e-23ea43acc28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing module_utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile module_utils.py\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*\n",
        "import bmf\n",
        "\n",
        "from bmf import VideoFrame\n",
        "from bmf.lib._bmf.sdk import ffmpeg\n",
        "import bmf.hml.hmp as mp\n",
        "\n",
        "\n",
        "def generate_out_packets(packet, np_arr, out_fmt):\n",
        "    # video_frame = bmf.VideoFrame.from_ndarray(np_arr, format=out_fmt)\n",
        "    rgbformat = mp.PixelInfo(mp.kPF_RGB24)\n",
        "    image = mp.Frame(mp.from_numpy(np_arr), rgbformat)\n",
        "    video_frame = VideoFrame(image)\n",
        "\n",
        "    video_frame.pts = packet.get(VideoFrame).pts\n",
        "    video_frame.time_base = packet.get(VideoFrame).time_base\n",
        "\n",
        "    pkt = bmf.Packet(video_frame)\n",
        "    pkt.timestamp = packet.timestamp\n",
        "    return pkt\n",
        "\n",
        "\n",
        "class SyncModule(bmf.Module):\n",
        "    def __init__(self, node=None, nb_in=1, in_fmt=\"yuv420p\", out_fmt=\"yuv420p\"):\n",
        "        \"\"\"\n",
        "        nb_in: the number of frames for core_process function\n",
        "        in_fmt: the pixel format of frames for core_process function\n",
        "        out_fmt: the pixel format of frame returned by core_process function\n",
        "        \"\"\"\n",
        "        self._node = node\n",
        "\n",
        "        self._margin_num = (nb_in - 1) // 2\n",
        "        self._out_frame_index = self._margin_num\n",
        "        self._in_frame_num = nb_in\n",
        "\n",
        "        self._in_fmt = in_fmt\n",
        "        self._out_fmt = out_fmt\n",
        "\n",
        "        self._in_packets = []\n",
        "        self._frames = []\n",
        "        self._eof = False\n",
        "\n",
        "    def process(self, task):\n",
        "\n",
        "        input_queue = task.get_inputs()[0]\n",
        "        # output_queue = task.get_outputs()[0]\n",
        "\n",
        "        while not input_queue.empty():\n",
        "            pkt = input_queue.get()\n",
        "            pkt_timestamp = pkt.timestamp\n",
        "\n",
        "            if pkt_timestamp == bmf.Timestamp.EOF:\n",
        "                self._eof = True\n",
        "                for _ in range(self._margin_num):\n",
        "                    self._in_packets.append(self._in_packets[-1])\n",
        "                    self._frames.append(self._frames[-1])\n",
        "                self._consume()\n",
        "\n",
        "                # output_queue.put(bmf.Packet.generate_eof_packet())\n",
        "                task.set_timestamp(bmf.Timestamp.DONE)\n",
        "                return bmf.ProcessResult.OK\n",
        "\n",
        "            pkt_data = pkt.get(VideoFrame)\n",
        "            if pkt_data is not None:\n",
        "                self._in_packets.append(pkt)\n",
        "                # self._frames.append(pkt.get(VideoFrame).to_ndarray(format=self._in_fmt))\n",
        "\n",
        "                self._frames.append(\n",
        "                    ffmpeg.reformat(pkt.get(VideoFrame), self._in_fmt)\n",
        "                    .frame()\n",
        "                    .plane(0)\n",
        "                    .numpy()\n",
        "                )\n",
        "\n",
        "            # padding first frame.\n",
        "            if len(self._in_packets) == 1:\n",
        "                for _ in range(self._margin_num):\n",
        "                    self._in_packets.append(self._in_packets[0])\n",
        "                    self._frames.append(self._frames[0])\n",
        "\n",
        "        self._consume()\n",
        "\n",
        "        return bmf.ProcessResult.OK\n",
        "\n",
        "    def _consume(self, output_queue=None):\n",
        "        while len(self._in_packets) >= self._in_frame_num:\n",
        "            out_frame = self.core_process(self._frames[: self._in_frame_num])\n",
        "            out_packet = generate_out_packets(\n",
        "                self._in_packets[self._out_frame_index], out_frame, self._out_fmt\n",
        "            )\n",
        "            # output_queue.put(out_packet)\n",
        "            self._in_packets.pop(0)\n",
        "            self._frames.pop(0)\n",
        "\n",
        "    def core_process(self, frames):\n",
        "        \"\"\"\n",
        "        user defined, process frames to output one frame, pass through by default\n",
        "        frames: input frames, list format\n",
        "        \"\"\"\n",
        "        return frames[0]\n",
        "\n",
        "    def clean(self):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        self.clean()\n",
        "\n",
        "    def reset(self):\n",
        "        self._eof = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3An0nCEm7zXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce935dc-95a2-41e8-ff89-bb64915e0462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "option {'output_path': 'res2.json'}\n",
            "decode_params {'input_path': 'bbb_360_20s.mp4', 'video_params': {'extract_frames': {'fps': 1}}}\n",
            "/content aesmod_module.BMFAesmod\n",
            "{\n",
            "    \"input_streams\": [],\n",
            "    \"output_streams\": [],\n",
            "    \"nodes\": [\n",
            "        {\n",
            "            \"module_info\": {\n",
            "                \"name\": \"c_ffmpeg_decoder\",\n",
            "                \"type\": \"\",\n",
            "                \"path\": \"\",\n",
            "                \"entry\": \"\"\n",
            "            },\n",
            "            \"meta_info\": {\n",
            "                \"premodule_id\": -1,\n",
            "                \"callback_binding\": []\n",
            "            },\n",
            "            \"option\": {\n",
            "                \"input_path\": \"bbb_360_20s.mp4\",\n",
            "                \"video_params\": {\n",
            "                    \"extract_frames\": {\n",
            "                        \"fps\": 1\n",
            "                    }\n",
            "                }\n",
            "            },\n",
            "            \"input_streams\": [],\n",
            "            \"output_streams\": [\n",
            "                {\n",
            "                    \"identifier\": \"video:c_ffmpeg_decoder_0_1\",\n",
            "                    \"stream_alias\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"input_manager\": \"immediate\",\n",
            "            \"scheduler\": 0,\n",
            "            \"alias\": \"\",\n",
            "            \"id\": 0\n",
            "        },\n",
            "        {\n",
            "            \"module_info\": {\n",
            "                \"name\": \"aesmod_module\",\n",
            "                \"type\": \"\",\n",
            "                \"path\": \"/content\",\n",
            "                \"entry\": \"aesmod_module.BMFAesmod\"\n",
            "            },\n",
            "            \"meta_info\": {\n",
            "                \"premodule_id\": -1,\n",
            "                \"callback_binding\": []\n",
            "            },\n",
            "            \"option\": {\n",
            "                \"output_path\": \"res2.json\"\n",
            "            },\n",
            "            \"input_streams\": [\n",
            "                {\n",
            "                    \"identifier\": \"c_ffmpeg_decoder_0_1\",\n",
            "                    \"stream_alias\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"output_streams\": [],\n",
            "            \"input_manager\": \"immediate\",\n",
            "            \"scheduler\": 0,\n",
            "            \"alias\": \"\",\n",
            "            \"id\": 1\n",
            "        }\n",
            "    ],\n",
            "    \"option\": {},\n",
            "    \"mode\": \"Normal\"\n",
            "}\n",
            "/content/models/aes_transonnx_update3.onnx\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n",
            "after preprocess shape (1, 3, 448, 672)\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import bmf\n",
        "import cv2, os, sys\n",
        "\n",
        "def get_duration(video_path):\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "    fps = capture.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
        "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps\n",
        "    capture.release()\n",
        "    return duration\n",
        "\n",
        "def segment_decode_ticks(video_path, seg_dur=4.0, lv1_dur_thres=24.0, max_dur=1000):\n",
        "    '''\n",
        "        bmf module new decode duration ticks\n",
        "        - 0 < Duration <= 24s, 抽帧间隔r=1, 抽帧0~24帧\n",
        "        - 24s < Duration <= 600s 分片抽取, 抽帧间隔r=1, 抽帧24帧\n",
        "            - 6个4s切片, 共计6x4=24帧\n",
        "        - duration > 600s, 分8片抽帧r=1, 抽帧数量32帧\n",
        "            - (600, inf), 8个4s切片, 共计8x4=32帧\n",
        "        最大解码长度 max_dur: 1000s\n",
        "    '''\n",
        "    duration = get_duration(video_path)\n",
        "    duration_ticks = []\n",
        "    if duration < lv1_dur_thres:\n",
        "        return dict()\n",
        "    elif duration <= 600:  # medium duration\n",
        "        seg_num = 6\n",
        "        seg_intev = (duration - seg_num * seg_dur) / (seg_num - 1)\n",
        "        if seg_intev < 0.5:\n",
        "            duration_ticks.extend([0, duration])\n",
        "        else:\n",
        "            for s_i in range(seg_num):\n",
        "                seg_init = s_i * (seg_dur + seg_intev)\n",
        "                seg_end = seg_init + seg_dur\n",
        "                duration_ticks.extend([round(seg_init, 3), round(seg_end, 3)])\n",
        "    else:  # long duration\n",
        "        seg_num = 8\n",
        "        seg_intev = (min(duration, max_dur) - seg_num * seg_dur) / (seg_num - 1)\n",
        "        for s_i in range(seg_num):\n",
        "            seg_init = s_i * (seg_dur + seg_intev)\n",
        "            seg_end = seg_init + seg_dur\n",
        "            duration_ticks.extend([round(seg_init, 3), round(seg_end, 3)])\n",
        "    return {'durations': duration_ticks}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  input_path = \"bbb_360_20s.mp4\"\n",
        "  outp_path = 'res2.json'\n",
        "\n",
        "  option = dict()\n",
        "  option['output_path'] = outp_path\n",
        "  print('option',option)\n",
        "  duration_segs = segment_decode_ticks(input_path)\n",
        "  decode_params = {'input_path': input_path, 'video_params': {'extract_frames': {'fps': 1}}}\n",
        "  decode_params.update(duration_segs)\n",
        "  print('decode_params',decode_params)\n",
        "  # module process\n",
        "\n",
        "  py_module_path = os.path.abspath(os.path.dirname(os.path.dirname('__file__')))\n",
        "  py_entry = 'aesmod_module.BMFAesmod'\n",
        "  print(py_module_path, py_entry)\n",
        "\n",
        "  streams = bmf.graph().decode(decode_params)\n",
        "  video_stream = streams['video'].module('aesmod_module',\n",
        "                                        option,\n",
        "                                        py_module_path,\n",
        "                                        py_entry)\n",
        "  video_stream.run()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat res2.json"
      ],
      "metadata": {
        "id": "IgzO4K01jdjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddfe7a0-5851-4671-a128-e793266564b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"aesthetic\": 73.96,\n",
            "    \"aesthetic_version\": \"v1.0\"\n",
            "}"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}